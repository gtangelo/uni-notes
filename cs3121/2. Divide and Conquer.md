# Divide & Conquer



## Counterfeit Coin Puzzle

> We are given 27 coins of the same denomination; we know that one of them is counterfeit and that it is lighter than the others. Find the counterfeit coin by weighing coins on a pan balance only three times.

Split the coins into three groups of nine. Place two groups on the balance. There are three outcomes:

1. The balance is tilted on the left, so counterfeit coin is in the right group
2. The balance is tilted on the right, so counterfeit coin is in the left group
3. The balance is evenly distributed, so counterfeit coin is in the remaining unchosen group

Repeat the same process on the chosen group (split the 9 coins into three groups of 3). Repeat the same process on the 3 coins. This methodology is known as **divide and conquer**.

## Counting Inversions

An *inversion* is a pair $(i, j)$ such that $i < j$ but $a[i] > a[j]$.

To count the number of inversions in an array $A$, we need to tweak the $\text{Merge-Sort}$ algorithm, by extending it to recursively both sort $A$ **and** determine the number of inversions in $A$.

- Split $A$ into two (approximately) equal parts $A_{top} = A[1 \dots \lfloor \frac{n}{2} \rfloor]$ and $A_{bottom} = [\lfloor \frac{n}{2} \rfloor + 1 \dots n]$.
- Recursively sort arrays $A_{top}$ and $A_{bottom}$ and obtain the number of inversions $I(A_{top})$ and $I(A_{bottom})$ respectively
- Merge $A_{top}$ and $A_{bottom}$ while counting the number of inversions across the two sub-arrays

## Adding Two Numbers

- Adding 3 bits (carry and two numbers) can be done in constant time
- Addition runs in linear time ($\mathcal{O}(n)$ many steps)
  - Cannot be made faster since the algorithm needs to read every bit of input

## Multiplying Two Numbers

- Assume that two $X$'s can be multiplied in constant time
- Algorithm runs in $\mathcal{O}(n^2)$ time

### Divide & Conquer Approach

Take two input numbers, $A$ and $B$ and split them in two halves $A = A_1 \cdot 2^{\frac{n}{2}} + A_0$ and $B = B_1 \cdot 2^{\frac{n}{2}} + B_0$ where $A_1$ and $B_1$ are the most significant bits and $A_0$ and $B_0$ are the least significant bits.

$AB$ can now be calculated as $AB = A_1 B_1 2^n + (A_1 B_0 + B_1 A_0) 2^{\frac{n}{2}} + A_0 B_0$.

The product $AB$ can be calculated recursively as follows:

```c
function Mult(A, B) {
  if |A| == |B| == 1 then return AB
  else
    A_1 = MoreSignificantPart(A);
    A_0 = LessSignificantPart(A);
    B_1 = MoreSignificantPart(B);
    B_0 = LessSignificantPart(B);
    X   = Mult(A_0, B_0);
    Y   = Mult(A_0, B_1);
    Z   = Mult(A_1, B_0);
    W   = Mult(A_1, B_1);
    return W * 2^n + (Y + Z) * 2^(n/2) + X;
  end if
}
```

Each multiplication of two $n$ digit numbers is replaced by four multiplications of $\frac{n}{2}$ digit numbers: $A_1, B_1$, $A_1, B_0$, $B_1, A_0$ and $A_0, B_0$, plus we have a linear overhead to shift and add: $T(n) = 4T (\frac{n}{2}) + cn$.

**Claim**: if $T(n)$ satisfies $T(n) = 4T (\frac{n}{2}) + cn$ then $T(n) = n^2 (c + 1) - cn$.

**Proof**: by 'fast' induction. We assume it is true for $\frac{n}{2}$: $T(\frac{n}{2}) = (\frac{n}{2})^2 (c + 1) - c \frac{n}{2}$ and prove it is also true for $n$: 

$$
\begin{array}{lcl}
  T(n) & = & 4T (\frac{n}{2}) + cn \\
  & = & 4 ((\frac{n}{2})^2 (c + 1) - \frac{n}{2}c) + cn \\
  & = & n^2 (c + 1) - 2cn + cn \\
  & = & n^2(c + 1) - cn \\
  & \equiv & \mathcal{O}(n^2)
\end{array}
$$

So, we gained nothing with the divide and conquer method.

### The Karatsuba Trick

Again, we split $A$ and $B$ into two halves $A = A_1 \cdot 2^{\frac{n}{2}} + A_0$ and $B = B_1 \cdot 2^{\frac{n}{2}} + B_0$.

We then calculate $AB$ as $AB = A_1 B_1 2^n = ((A_1 + A_0)(B_1 + B_0) - A_1 B_1 - A_0 B_0) 2^{\frac{n}{2}} + A_0 B_0$, saving us one multiplication at each recursion round.

The algorithm is as follows:

```c
function Mult(A, B) {
  if |A| == |B| == 1 then return AB
  else
    A_1 = MoreSignificantPart(A);
    A_0 = LessSignificantPart(A);
    B_1 = MoreSignificantPart(B);
    B_0 = LessSignificantPart(B);
    U   = A_0 + A_1;
    V   = B_0 + B_1;
    X   = Mult(A_0, B_0);
    W   = Mult(A_1, B_1);
    Y   = Mult(U, V);
    return W * 2^n + (Y - X - W) * 2^(n/2) + X;
  end if
}
```

The runtime $T(n)$ of this algorithm satisfies $T(n) = 3T (\frac{n}{2}) + cn$.

- Replacing $n$ with $\frac{n}{2}$ we get $T(\frac{n}{2}) = 3T (\frac{n}{n^2}) + c \frac{n}{2}$
- Replacing $n$ with $\frac{n}{2^2}$ we get $T(\frac{n}{n^2}) = 3T (\frac{n}{2^3}) + c \frac{n}{2^2}$

So

$$
\begin{array}{lcl}
  T(n) & = & 3T (\frac{n}{2}) + \frac{cn}{2} \\
  & = & 3 [3T (\frac{n}{2^2}) + \frac{cn}{2}] + cn \\
  & = & 3^2T (\frac{n}{2^2}) + nc [1 + \frac{3}{2}] \\
  & \vdots & \\
  & = & 3^{\lfloor \log_2 n \rfloor} T (\frac{n}{\lfloor \log_2 n \rfloor}) + cn [1 + \frac{3}{2} + \cdots + (\frac{3}{2})^{\lfloor \log_2 n \rfloor - 1}] \\
  & = & 3^{\lor_2 n} T(1) + cn [\frac{(3/2)^{\log_2 n} - 1}{3/2 - 1}] \\
  & \simeq & 3^{\log_2 n} T(1) = 2cn [(\frac{3}{2}^{\log_2 n}) - 1]
\end{array}
$$

Then using the fact that $a^{\log_b n} = n^{\log_b a}$ we have

$$
\begin{array}{lcl}
  T(n) & = & n^{\log_2 3} T(1) + 2cn [n^{\log_2 (3/2)} - 1] \\
  & = & n^{\log_2 3} T(1) + 2cn [n^{\log_2 3 - 1} - 1] \\
  & = & n^{\log_2 3} T(1) + 2c \cdot n^{\log_2 3} - 2cn \\
  & = & \mathcal{O}(n^{\log_2 3}) \\
  & = & \mathcal{O}(n^{1.58\dots}) < \mathcal{O}(n^2)
\end{array}
$$
